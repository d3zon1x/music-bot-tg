# utils/download.py

import os
import urllib.parse

import requests
import yt_dlp
import logging
from bs4 import BeautifulSoup
from PIL import Image

from config import GENIUS_API_KEY
from utils.sanitize import sanitize_filename, format_duration, format_filesize

def normalize_youtube_url(url: str) -> str:
    """
    –ü—Ä–∏–π–º–∞—î –±—É–¥—å-—è–∫–µ –ø–æ—Å–∏–ª–∞–Ω–Ω—è YouTube —ñ –ø–æ–≤–µ—Ä—Ç–∞—î –∫–∞–Ω–æ–Ω—ñ—á–Ω–µ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –≤–∏–¥—É:
    "https://www.youtube.com/watch?v=VIDEO_ID"
    """
    parsed = urllib.parse.urlparse(url)
    video_id = None
    hostname = parsed.hostname.lower() if parsed.hostname else ''
    if hostname in ['youtu.be']:
        video_id = parsed.path.lstrip('/')
    elif hostname in ['www.youtube.com', 'youtube.com']:
        qs = urllib.parse.parse_qs(parsed.query)
        video_id = qs.get('v', [None])[0]
        # –Ø–∫—â–æ video_id –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ, –ø–µ—Ä–µ–≤—ñ—Ä–∏–º–æ, —á–∏ —î /embed/ –∞–±–æ /v/ —É —à–ª—è—Ö—É
        if not video_id and parsed.path:
            path_parts = parsed.path.split('/')
            if 'embed' in path_parts or 'v' in path_parts:
                video_id = path_parts[-1]
    if video_id:
        return f"https://www.youtube.com/watch?v={video_id}"
    return url

async def fetch_youtube_metadata(query):
    """
    –û—Ç—Ä–∏–º—É—î –±–∞–∑–æ–≤—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ —Ç—Ä–µ–∫ (–±–µ–∑ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è):
      - title (–Ω–∞–∑–≤–∞)
      - duration (—Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å, —Å–µ–∫)
      - uploader (–∫–∞–Ω–∞–ª/–≤–∏–∫–æ–Ω–∞–≤–µ—Ü—å)
      - thumbnail (URL –æ–±–∫–ª–∞–¥–∏–Ω–∫–∏)
    –ü–æ–≤–µ—Ä—Ç–∞—î —Å–ª–æ–≤–Ω–∏–∫ –∑ —Ü–∏–º–∏ –ø–æ–ª—è–º–∏.
    """
    if query.startswith("http"):
        normalized_query = normalize_youtube_url(query)
        search_str = normalized_query
    else:
        search_str = f"ytsearch:{query}"

    logging.info(f"üîé –û—Ç—Ä–∏–º—É—é –º–µ—Ç–∞–¥–∞–Ω—ñ –¥–ª—è: {search_str}")

    ydl_opts = {
        'format': 'bestaudio/best',
        'outtmpl': 'music/%(title)s.%(ext)s',
    }
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        info = ydl.extract_info(search_str, download=False)
        if 'entries' in info:
            info = info['entries'][0]
        meta = {
            'title': info.get('title', 'Unknown'),
            'duration': info.get('duration', 0),
            'uploader': info.get('uploader', 'Unknown'),
            'thumbnail': info.get('thumbnail', None),
        }
    return meta

async def download_music(query):
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –∞—É–¥—ñ–æ (–ø–µ—Ä—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç) –∑–∞ –∑–∞–ø–∏—Ç–æ–º.
    –Ø–∫—â–æ query —î URL, –Ω–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ –π–æ–≥–æ, —ñ–Ω–∞–∫—à–µ –¥–æ–¥–∞—î–º–æ "ytsearch:".
    –ü–æ–≤–µ—Ä—Ç–∞—î —à–ª—è—Ö –¥–æ .mp3-—Ñ–∞–π–ª—É –∞–±–æ None, —è–∫—â–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.
    """
    logging.info(f"üéµ –ó–∞–≤–∞–Ω—Ç–∞–∂—É—é –º—É–∑–∏–∫—É: {query}")
    if query.startswith("http"):
        search_query = normalize_youtube_url(query)
    else:
        search_query = f"ytsearch:{query}"

    ydl_opts = {
        'format': 'bestaudio/best',
        'outtmpl': 'music/%(title)s.%(ext)s',
        'postprocessors': [{
            'key': 'FFmpegExtractAudio',
            'preferredcodec': 'mp3',
            'preferredquality': '192',
        }],
    }
    from yt_dlp import YoutubeDL
    with YoutubeDL(ydl_opts) as ydl:
        info = ydl.extract_info(search_query, download=True)
        if 'entries' in info:
            if not info['entries']:
                raise ValueError("No entries found for the query")
            info = info['entries'][0]
        filename = ydl.prepare_filename(info)
        filename = filename.replace('.webm', '.mp3').replace('.m4a', '.mp3')
        if os.path.exists(filename):
            logging.info(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ —Ñ–∞–π–ª: {filename}")
            return filename
        else:
            logging.error(f"‚ùå –§–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {filename}")
            return None

async def download_music_with_metadata(query):
    """
    –°–ø–æ—á–∞—Ç–∫—É –æ—Ç—Ä–∏–º—É—î –º–µ—Ç–∞–¥–∞–Ω—ñ —á–µ—Ä–µ–∑ fetch_youtube_metadata,
    –ø–æ—Ç—ñ–º –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î –∞—É–¥—ñ–æ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é download_music.
    –ü–æ–≤–µ—Ä—Ç–∞—î –∫–æ—Ä—Ç–µ–∂: (filename, title, duration, uploader, thumbnail)
    """
    meta = await fetch_youtube_metadata(query)
    title = meta.get('title', 'Unknown')
    duration = meta.get('duration', 0)
    uploader = meta.get('uploader', 'Unknown')
    thumbnail = meta.get('thumbnail', None)
    filename = await download_music(query)
    return filename, title, duration, uploader, thumbnail

async def download_thumbnail(url, out_path='thumb.jpg', max_size_kb=200):
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î thumbnail –∑–∞ URL —ñ –∑–º–µ–Ω—à—É—î –π–æ–≥–æ, –ø–æ–∫–∏ –Ω–µ —Å—Ç–∞–Ω–µ –º–µ–Ω—à–µ max_size_kb (—É KB).
    –ü–æ–≤–µ—Ä—Ç–∞—î —à–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É –∞–±–æ None, —è–∫—â–æ –Ω–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏.
    """
    if not url:
        return None
    try:
        r = requests.get(url, timeout=10)
        if r.status_code != 200:
            logging.error(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ thumbnail: —Å—Ç–∞—Ç—É—Å {r.status_code}")
            return None
        with open(out_path, 'wb') as f:
            f.write(r.content)
        if os.path.getsize(out_path) > max_size_kb * 1024:
            img = Image.open(out_path)
            img.thumbnail((320, 320))
            img.save(out_path, optimize=True, quality=85)
            # –Ø–∫—â–æ –≤—Å–µ —â–µ –ø–µ—Ä–µ–≤–∏—â—É—î –ª—ñ–º—ñ—Ç, –∑–º–µ–Ω—à—É—î–º–æ —è–∫—ñ—Å—Ç—å
            while os.path.getsize(out_path) > max_size_kb * 1024:
                img = Image.open(out_path)
                img.save(out_path, optimize=True, quality=70)
        return out_path
    except Exception as e:
        logging.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è thumbnail: {e}")
        return None

async def search_music(query, max_results=1):
    """
    –í–∏–∫–æ–Ω—É—î –ø–æ—à—É–∫ –º—É–∑–∏–∫–∏ –∑–∞ –∑–∞–ø–∏—Ç–æ–º (–±–µ–∑ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—ñ–≤) —Ç–∞ –ø–æ–≤–µ—Ä—Ç–∞—î —Å–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤.
    –ü–æ–≤–µ—Ä—Ç–∞—î —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–Ω–∏–∫—ñ–≤, –∫–æ–∂–µ–Ω –º—ñ—Å—Ç–∏—Ç—å 'title', 'duration', 'uploader' —Ç–∞ 'url' (–ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ YouTube).
    """
    ydl_opts = {
        'format': 'bestaudio/best',
        'outtmpl': 'music/%(title)s.%(ext)s',
    }
    results = []
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ ytsearchN, –¥–µ N ‚Äî –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        info = ydl.extract_info(f"ytsearch{max_results}:{query}", download=False)
        if 'entries' in info:
            for entry in info['entries']:
                result = {
                    'title': entry.get('title', 'Unknown'),
                    'duration': entry.get('duration', 0),
                    'uploader': entry.get('uploader', 'Unknown'),
                    'url': entry.get('webpage_url', '')
                }
                results.append(result)
    return results

async def get_lyrics(song_query):
    search_url = f"https://api.genius.com/search?q={song_query}"
    headers = {"Authorization": f"Bearer {GENIUS_API_KEY}"}

    try:
        response = requests.get(search_url, headers=headers, timeout=10)
        data = response.json()
        hits = data.get("response", {}).get("hits", [])
        if not hits:
            logging.error("‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –¥–ª—è –ø–æ—à—É–∫—É –ª—ñ—Ä–∏–∫–∏.")
            return None
        song_url = hits[0]["result"]["url"]
    except Exception as e:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø–æ—à—É–∫—É –≤ Genius API: {e}")
        return None

    # –°–∫—Ä–∞–ø–∏–º–æ —Ç–µ–∫—Å—Ç –ø—ñ—Å–Ω—ñ –∑ URL —Å—Ç–æ—Ä—ñ–Ω–∫–∏
    headers_scrape = {"User-Agent": "Mozilla/5.0"}
    try:
        page = requests.get(song_url, headers=headers_scrape, timeout=10)
        if page.status_code != 200:
            logging.error(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Å—Ç–æ—Ä—ñ–Ω–∫—É –∑ –ª—ñ—Ä–∏–∫–æ—é: —Å—Ç–∞—Ç—É—Å {page.status_code}")
            return None

        soup = BeautifulSoup(page.text, "html.parser")
        # Genius –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –Ω–æ–≤–∏–π markup: —à—É–∫–∞—î–º–æ –≤—Å—ñ div –∑ data-lyrics-container="true"
        containers = soup.find_all("div", attrs={"data-lyrics-container": "true"})
        if not containers:
            logging.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ –µ–ª–µ–º–µ–Ω—Ç–∏ –∑ —Ç–µ–∫—Å—Ç–æ–º –ø—ñ—Å–Ω—ñ.")
            return None

        lyrics = "\n".join([container.get_text(separator="\n", strip=True) for container in containers])
        return lyrics.strip()
    except Exception as e:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —Å–∫—Ä–∞–ø—ñ–Ω–≥—É –ª—ñ—Ä–∏–∫–∏: {e}")
        return None

async def recognize_song(file_path):
    """
    –†–æ–∑–ø—ñ–∑–Ω–∞—î –ø—ñ—Å–Ω—é —á–µ—Ä–µ–∑ Audd.io.
    –ü–æ–≤–µ—Ä—Ç–∞—î –Ω–∞–∑–≤—É —Ç—Ä–µ–∫—É –∞–±–æ '–ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ —Ç—Ä–µ–∫'.
    """
    url = "https://api.audd.io/"
    data = {"api_token": "b158e7438fe38dde1f0990e3fd6bfd29"}
    try:
        with open(file_path, "rb") as f:
            files = {"file": f}
            response = requests.post(url, data=data, files=files).json()
        if "result" in response and response["result"]:
            return response["result"].get("title", "–ù–µ–≤—ñ–¥–æ–º–æ")
        else:
            return "–ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ —Ç—Ä–µ–∫"
    except Exception as e:
        logging.error(f"–ü–æ–º–∏–ª–∫–∞ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —Ç—Ä–µ–∫—É: {e}")
        return "–ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ —Ç—Ä–µ–∫"

